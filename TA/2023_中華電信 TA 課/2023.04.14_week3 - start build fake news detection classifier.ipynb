{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1noxMAIiW0cC-1xDghZh7IKaY23280URf","timestamp":1685953286876}],"private_outputs":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# 資料探戡：分類"],"metadata":{"id":"UXvuTxsAAA0t"}},{"cell_type":"markdown","source":["使用 Kaggle 資料集：\n","\n","*   [Fake and real news dataset](https://drive.google.com/file/d/10oJKD6_eHRNSnAcwtlYWg25Z_pMHxubT/view?usp=share_link)\n","\n","\n","\n"],"metadata":{"id":"1FEVchipER0K"}},{"cell_type":"code","source":["# 下載真假新聞壓縮檔\n","!wget --no-check-certificate \"https://drive.google.com/uc?export=download&id=10oJKD6_eHRNSnAcwtlYWg25Z_pMHxubT&confirm=t\" -O fakenews.zip\n","!unzip fakenews.zip"],"metadata":{"id":"N-DJSamk5ZON"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 讀入資料集 -- fakenews : training & test set\n","import pandas as pd\n","\n","df_train = pd.read_csv('train.csv')\n","df_test = pd.read_csv('test.csv')\n","\n","# 看看訓練資料欄位\n","print(df_train.info())"],"metadata":{"id":"wqoyBMWjD4Sd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 看看 test set\n","print(df_test.info())"],"metadata":{"id":"uj8vlyRQ_A74"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 本日競賽：【CHT盃】真假（英文）新聞辨識\n","\n","挑戰層層關卡：\n","*   用選擇的、或清洗後的training set，訓練模型。\n","*   模型可用任一個已教過的分類器：KNN、Logistic regression、Naive Bayesian Classifier\n","*   使用此模型，預測 test set 哪則為真？哪則為假？預測結果請存至 \"predicted\" 欄位。\n","*   測試集共有8979筆資料。請保留\"id\" 及 \"predicted\" 兩個欄位，並存成csv格式。\n","*   將你存好的csv，上傳到競賽網頁：http://140.119.108.249:20234\n","### *   排名前五名的同學，將獲得精美小禮品，及好寶寶獎章一枚！\n","\n"],"metadata":{"id":"Kn9Kh2ps_B54"}},{"cell_type":"code","source":["# 不訓練模型，而使用一個極爛招：隨機猜新聞的真假！\n","import pandas as pd\n","import numpy as np\n","\n","\n","input_df = pd.read_csv('test.csv')\n","guess_df = input_df['id'] # 還是要欄位 id\n","# 真新聞:　１； 假新聞 : 0\n","df_guess = pd.DataFrame( np.random.randint(0, 2, size=len(input_df)), columns=['predicted'] )\n","guess_df = pd.concat( [guess_df, df_guess], axis = 1 )\n","\n","# 存檔。此亂猜的結果，已作為 baseline 上傳。\n","guess_df.to_csv('random_guess.csv', index=False)"],"metadata":{"id":"j4Gvy8o5_Am6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 要如何進行資料前處理？\n","\n","\n","*   是否要進一步計算特徵？\n","*   是否要 clean data？\n","\n"],"metadata":{"id":"_Sf5KtHPE7Pi"}},{"cell_type":"code","source":["# 使用 nltk 做斷詞\n","import nltk\n","from nltk.corpus import stopwords\n","\n","# 必須先下載模型、語料\n","nltk.download('punkt')\n","\n","# 導入停止詞\n","nltk.download('stopwords')\n","\n","# Lemmatize\n","nltk.download('wordnet')"],"metadata":{"id":"dN4kKWN7_onZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","\n","lemmatizer = WordNetLemmatizer()\n","stop_words = set(stopwords.words('english'))\n","\n","def preprocess_text(text):\n","    # Parse the text with Spacy\n","    doc = word_tokenize(text)\n","\n","    # Lemmatize the tokens and remove stop words\n","    lemmas = [lemmatizer.lemmatize(token) for token in doc if token.lower() not in stop_words]\n","\n","    \n","    # Join the lemmas back into a string and return it\n","    return \" \".join(lemmas)\n"],"metadata":{"id":"ZllvThrSBO4L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tqdm.auto import tqdm\n","import time"],"metadata":{"id":"rbxAMslvC7OY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 資料多，應該會跑一段時間喔！\n","%%time\n","\n","tqdm.pandas()\n","\n","df_train['text_lemma'] = df_train['text'].progress_apply(preprocess_text)"],"metadata":{"id":"JFxMoViGCN9_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(df_train['text_lemma'])"],"metadata":{"id":"TExtXBBjmjjr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 因為今天有小競賽，所以 test set 已移除掉正確答案，\n","# 以下是從 training set，再切一塊　validate set，用它做模型評估用的資料集。\n","\n","from sklearn.model_selection import train_test_split\n","\n","# split the data into training and testing sets\n","X_train, X_val, y_train, y_val = train_test_split(df_train['text'], df_train['label'], test_size=0.2, random_state=42)\n","\n","# 看看切割後的　training & validation set\n","print('X_train shape:', X_train.shape)\n","print('X_Val shape:', X_val.shape)"],"metadata":{"id":"GkkqDzhQ_BGg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 建立 Bag of word 的特徵\n","\n","簡言之，基於出現的字，進行詞頻統計，並視為向量化的資料。\n","\n","Ref: https://en.wikipedia.org/wiki/Bag-of-words_model"],"metadata":{"id":"lkWn7Q2lDqme"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","\n","# create bag-of-words features\n","vectorizer = CountVectorizer()\n","X_train_vect = vectorizer.fit_transform(X_train)\n","X_val_vect = vectorizer.transform(X_val)"],"metadata":{"id":"kwT96SCyDxII"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 可以看看 vector 的內容?\n","print(X_val_vect)"],"metadata":{"id":"riLmuGbuF4VM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 貝氏分類器\n","\n","\n","*   建立模型\n","*   使用模型預測驗證資料集(X_val)\n","*   使用模型預測測試資料集，並將結果上傳"],"metadata":{"id":"ZCXkHGBI_roq"}},{"cell_type":"code","source":["# 從這裡開始認真訓練模型\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import accuracy_score\n","\n","# (1) train a Naive Bayes classifier\n","clf_NB = MultinomialNB()\n","\n","clf_NB.fit(X_train_vect, y_train)"],"metadata":{"id":"MZjnHEy5Fore"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#　(2) Get prediction using validation set\n","y_pred = clf_NB.predict(X_val_vect)\n","\n","# check accuracy\n","acc = accuracy_score(y_val, y_pred)\n","print(\"Accuracy:\", acc)"],"metadata":{"id":"tdr_cLMRFeBG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check confusion matrix\n","from sklearn.metrics import confusion_matrix\n","\n","cm = confusion_matrix(y_val, y_pred)\n","print(cm)"],"metadata":{"id":"NBgQUsY9GOWx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check more matrics\n","from sklearn.metrics import classification_report\n","\n","# generate classification report\n","target_names = ['Fake', 'True']\n","print(classification_report(y_val, y_pred, target_names=target_names))"],"metadata":{"id":"hkqQCcxCGcdV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 看看 df_test\n","df_test.head()\n","\n","# (3) 用訓練好的 clf_NB 模型，預測 df_test 的結果\n","# 施主，這個你得自己試試看～"],"metadata":{"id":"Pp556LtSks8Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 你上傳結果並完成比賽了嗎？XD"],"metadata":{"id":"CThr94oAzQMI"}}]}